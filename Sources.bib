@book{mood1974,
  author    = {Mood, Alexander M. and Graybill, Franklin A. and Boes, Duane C.},
  title     = {Introduction to the Theory of Statistics},
  year      = {1974},
  publisher = {McGraw-Hill}
}

@book{augustin_introduction_2014,
	address = {Chichester, West Sussex},
	series = {Wiley series in probability and statistics},
	title = {Introduction to imprecise probabilities},
	isbn = {9780470973813},
	abstract = {In recent years, the theory has become widely accepted and has been further developed, but a detailed introduction is needed in order to make the material available and accessible to a wide audience. This will be the first book providing such an introduction, covering core theory and recent developments which can be applied to many application areas. All authors of individual chapters are leading researchers on the specific topics, assuring high quality and up-to-date contents. An Introduction to Imprecise Probabilities provides a comprehensive introduction to imprecise probabilities, including theory and applications reflecting the current state if the art. Each chapter is written by experts on the respective topics, including: Sets of desirable gambles; Coherent lower (conditional) previsions; Special cases and links to literature; Decision making; Graphical models; Classification; Reliability and risk assessment; Statistical inference; Structural judgments; Aspects of implementation (including elicitation and computation); Models in finance; Game-theoretic probability; Stochastic processes (including Markov chains); Engineering applications. Essential reading for researchers in academia, research institutes and other organizations, as well as practitioners engaged in areas such as risk analysis and engineering},
	language = {eng},
	publisher = {John Wiley \& Sons},
	editor = {Augustin, Thomas and Coolen, Frank P. A. and De Cooman, Gert and Troffaes, Matthias C. M.},
	year = {2014},
}

@article{balch_satellite_2019,
	title = {Satellite conjunction analysis and the false confidence theorem},
	volume = {475},
	issn = {1364-5021, 1471-2946},
	url = {https://royalsocietypublishing.org/doi/10.1098/rspa.2018.0565},
	doi = {10.1098/rspa.2018.0565},
	abstract = {Satellite conjunction analysis is the assessment of collision risk during a close encounter between a satellite and another object in orbit. A counterintuitive phenomenon has emerged in the conjunction analysis literature, namely, probability dilution, in which lower quality data paradoxically appear to reduce the risk of collision. We show that probability dilution is a symptom of a fundamental deficiency in probabilistic representations of statistical inference, in which there are propositions that will consistently be assigned a high degree of belief, regardless of whether or not they are true. We call this deficiency false confidence. In satellite conjunction analysis, it results in a severe and persistent underestimate of collision risk exposure. We introduce the Martin–Liu validity criterion as a benchmark by which to identify statistical methods that are free from false confidence. Such inferences will necessarily be non-probabilistic. In satellite conjunction analysis, we show that uncertainty ellipsoids satisfy the validity criterion. Performing collision avoidance manoeuvres based on ellipsoid overlap will ensure that collision risk is capped at the user-specified level. Furthermore, this investigation into satellite conjunction analysis provides a template for recognizing and resolving false confidence issues as they occur in other problems of statistical inference.},
	language = {en},
	number = {2227},
	urldate = {2025-05-19},
	journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Balch, Michael Scott and Martin, Ryan and Ferson, Scott},
	month = jul,
	year = {2019},
	pages = {20180565},
	file = {Volltext:/Users/maximwinter/Zotero/storage/6NHIFF32/Balch et al. - 2019 - Satellite conjunction analysis and the false confidence theorem.pdf:application/pdf},
}


@article{MIRANDA200532,
title = {Random sets as imprecise random variables},
journal = {Journal of Mathematical Analysis and Applications},
volume = {307},
number = {1},
pages = {32-47},
year = {2005},
issn = {0022-247X},
doi = {https://doi.org/10.1016/j.jmaa.2004.10.022},
url = {https://www.sciencedirect.com/science/article/pii/S0022247X04008571},
author = {Enrique Miranda and Inés Couso and Pedro Gil},
keywords = {Random sets, Upper and lower probabilities, Measurable selections, Choquet integral, Weak convergence},
abstract = {Given a random set coming from the imprecise observation of a random variable, we study how to model the information about the probability distribution of this random variable. Specifically, we investigate whether the information given by the upper and lower probabilities induced by the random set is equivalent to the one given by the class of the probabilities induced by the measurable selections; together with sufficient conditions for this, we also give examples showing that they are not equivalent in all cases.}
}

@InCollection{sep-dutch-book,
	author       =	{Vineberg, Susan},
	title        =	{{Dutch Book Arguments}},
	booktitle    =	{The {Stanford} Encyclopedia of Philosophy},
	editor       =	{Edward N. Zalta and Uri Nodelman},
	howpublished =	{\url{https://plato.stanford.edu/archives/fall2022/entries/dutch-book/}},
	year         =	{2022},
	edition      =	{{F}all 2022},
	publisher    =	{Metaphysics Research Lab, Stanford University}
}

@article{Fisher_1930, 
  title={Inverse Probability}, 
  volume={26}, DOI={10.1017/S0305004100016297}, 
  number={4}, journal={Mathematical Proceedings of the Cambridge Philosophical Society}, 
  author={Fisher, R. A.}, 
  year={1930}, 
  pages={528–535}
}

@article{aldrich_r_1997,
	title = {R.{A}. {Fisher} and the making of maximum likelihood 1912-1922},
	volume = {12},
	issn = {0883-4237},
	url = {https://projecteuclid.org/journals/statistical-science/volume-12/issue-3/RA-Fisher-and-the-making-of-maximum-likelihood-1912-1922/10.1214/ss/1030037906.full},
	doi = {10.1214/ss/1030037906},
	language = {en},
	number = {3},
	urldate = {2025-05-09},
	journal = {Statistical Science},
	author = {Aldrich, John},
	month = sep,
	year = {1997},
	file = {PDF:/Users/maximwinter/Zotero/storage/BBSHNDF7/Aldrich - 1997 - R.A. Fisher and the making of maximum likelihood 1912-1922.pdf:application/pdf},
}

@article{zabell_r_nodate,
	title = {R. {A}. {Fish}{\textasciitilde}r and the {Fiducial} {Argument}},
	abstract = {The fiducial argument arose from Fisher's desire to create an inferential alternative to inverse methods. Fisher discovered such an alternative in 1930, when he realized that pivotal quantities permit the derivation of probability statements concerning an unknown parameter independent of any assumption concerning its a priori distribution.},
	language = {en},
	author = {Zabell, S L},
	file = {PDF:/Users/maximwinter/Zotero/storage/9ALSQVM6/Zabell - R. A. Fish~r and the Fiducial Argument.pdf:application/pdf},
}

@book{a_n_kolmogorov_foundations_1950,
	title = {Foundations of the {Theory} of {Probability}},
	url = {http://archive.org/details/kolmogorov_202112},
	abstract = {The purpose of this monograph is to give an axiomatic foundation for the theory of probability. The author set himself the task of putting in their natural place, among the general notions of modern mathematics, the basic concepts of probability theory—concepts which until recently were considered to be quite peculiar.

This task would have been a rather hopeless one before the introduction of Lebesgue’s theories of measure and integration. However, after Lebesgue’s publication of his investigations, the analogies between measure of a set and probability of an event, and between integral of a function and mathematical expectation of a random variable, became apparent. These analogies allowed of further extensions; thus, for example, various properties of independent random variables were seen to be in complete analogy with the corresponding properties of orthogonal functions. But if probability theory was to be based on the above analogies, it still was necessary to make the theories of measure and integra­ tion independent of the geometric elements which were in the foreground with Lebesgue. This has been done by Frechet.

While a conception of probability theory based on the above general viewpoints has been current for some time among certain mathematicians, there was lacking a complete exposition of the whole system, free of extraneous complications. 

I wish to call attention to those points of the present exposition which are outside the above-mentioned range of ideas familiar to the specialist. They are the following: Probability distributions in infinite-dimensional spaces (Chapter III, § 4) ; differentiation and integration of mathematical expectations with respect to a parameter (Chapter IV, § 5) ; and especially the theory of condi­ tional probabilities and conditional expectations (Chapter V). It should be emphasized that these new problems arose, of neces­sity, from some perfectly concrete physical problems.

The sixth chapter contains a survey, without proofs, of some results of A. Khinchine and the author of the limitations on the applicability of the ordinary and of the strong law of large num­ bers. The bibliography contains some recent works which should be of interest from the point of view of the foundations of the subject.},
	language = {eng},
	urldate = {2025-05-12},
	author = {{A. N. Kolmogorov}},
	year = {1950},
	keywords = {probability theory},
}

@InCollection{sep-hilbert-program,
	author       =	{Zach, Richard},
	title        =	{{Hilbert’s Program}},
	booktitle    =	{The {Stanford} Encyclopedia of Philosophy},
	editor       =	{Edward N. Zalta and Uri Nodelman},
	howpublished =	{\url{https://plato.stanford.edu/archives/win2023/entries/hilbert-program/}},
	year         =	{2023},
	edition      =	{{W}inter 2023},
	publisher    =	{Metaphysics Research Lab, Stanford University}
}

@InCollection{sep-probability-interpret,
	author       =	{Hájek, Alan},
	title        =	{{Interpretations of Probability}},
	booktitle    =	{The {Stanford} Encyclopedia of Philosophy},
	editor       =	{Edward N. Zalta and Uri Nodelman},
	howpublished =	{\url{https://plato.stanford.edu/archives/win2023/entries/probability-interpret/}},
	year         =	{2023},
	edition      =	{{W}inter 2023},
	publisher    =	{Metaphysics Research Lab, Stanford University}
}

@book{carnap_logical_1950,
	title = {Logical foundations of probability},
	copyright = {Copyright review: Public domain according to HathiTrust rights database},
	url = {http://archive.org/details/logicalfoundatio00carn_0},
	abstract = {xvii, 607 pages; Bibliography: pages 583-598},
	language = {eng},
	urldate = {2025-05-13},
	publisher = {Chicago : University of Chicago Press},
	author = {Carnap, Rudolf},
	collaborator = {{Princeton Theological Seminary Library}},
	year = {1950},
	keywords = {Probabilities},
}

@article{martin_false_2019,
	title = {False confidence, non-additive beliefs, and valid statistical inference},
	volume = {113},
	issn = {0888613X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0888613X19300696},
	doi = {10.1016/j.ijar.2019.06.005},
	language = {en},
	urldate = {2025-05-17},
	journal = {International Journal of Approximate Reasoning},
	author = {Martin, Ryan},
	month = oct,
	year = {2019},
	pages = {39--73},
	file = {Eingereichte Version:/Users/maximwinter/Zotero/storage/ZXSXN8E3/Martin - 2019 - False confidence, non-additive beliefs, and valid statistical inference.pdf:application/pdf},
}

@article{zimmermann_fuzzy_2010,
	title = {Fuzzy set theory},
	volume = {2},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	issn = {1939-5108, 1939-0068},
	url = {https://wires.onlinelibrary.wiley.com/doi/10.1002/wics.82},
	doi = {10.1002/wics.82},
	abstract = {Abstract
            Since its inception in 1965, the theory of fuzzy sets has advanced in a variety of ways and in many disciplines. Applications of this theory can be found, for example, in artificial intelligence, computer science, medicine, control engineering, decision theory, expert systems, logic, management science, operations research, pattern recognition, and robotics. Mathematical developments have advanced to a very high standard and are still forthcoming to day. In this review, the basic mathematical framework of fuzzy set theory will be described, as well as the most important applications of this theory to other theories and techniques. Since 1992 fuzzy set theory, the theory of neural nets and the area of evolutionary programming have become known under the name of ‘computational intelligence’ or ‘soft computing’. The relationship between these areas has naturally become particularly close. In this review, however, we will focus primarily on fuzzy set theory. Applications of fuzzy set theory to real problems are abound. Some references will be given. To describe even a part of them would certainly exceed the scope of this review. Copyright © 2010 John Wiley \& Sons, Inc.
            
              This article is categorized under:
              
                
                  Statistical Learning and Exploratory Methods of the Data Sciences {\textgreater} Clustering and Classification},
	language = {en},
	number = {3},
	urldate = {2025-05-18},
	journal = {WIREs Computational Statistics},
	author = {Zimmermann, H.‐J.},
	month = may,
	year = {2010},
	pages = {317--332},
}


@misc{shafer_origins_2018,
	title = {The origins and legacy of {Kolmogorov}'s {Grundbegriffe}},
	url = {http://arxiv.org/abs/1802.06071},
	doi = {10.48550/arXiv.1802.06071},
	abstract = {April 25, 2003, marked the 100th anniversary of the birth of Andrei Nikolaevich Kolmogorov, the twentieth century's foremost contributor to the mathematical and philosophical foundations of probability. The year 2003 was also the 70th anniversary of the publication of Kolmogorov's Grundbegriffe der Wahrscheinlichkeitsrechnung. Kolmogorov's Grundbegriffe put probability's modern mathematical formalism in place. It also provided a philosophy of probability - an explanation of how the formalism can be connected to the world of experience. In this article, we examine the sources of these two aspects of the Grundbegriffe - the work of the earlier scholars whose ideas Kolmogorov synthesized.},
	urldate = {2025-05-12},
	publisher = {arXiv},
	author = {Shafer, Glenn and Vovk, Vladimir},
	month = feb,
	year = {2018},
	note = {arXiv:1802.06071 [math]},
	keywords = {Mathematics - History and Overview, Mathematics - Probability},
	annote = {Comment: 104 pages. arXiv admin note: substantial text overlap with arXiv:math/0606533},
	file = {Full Text PDF:/Users/maximwinter/Zotero/storage/SRW468D6/Shafer und Vovk - 2018 - The origins and legacy of Kolmogorov's Grundbegriffe.pdf:application/pdf;Snapshot:/Users/maximwinter/Zotero/storage/YIT6WX43/1802.html:text/html},
}

@book{cox_theoretical_1979,
	title = {Theoretical {Statistics}},
	isbn = {978-0-412-16160-5},
	abstract = {A text that stresses the general concepts of the theory of statistics Theoretical Statistics provides a systematic statement of the theory of statistics, emphasizing general concepts rather than mathematical rigor. Chapters 1 through 3 provide an overview of statistics and discuss some of the basic philosophical ideas and problems behind statistical procedures. Chapters 4 and 5 cover hypothesis testing with simple and null hypotheses, respectively. Subsequent chapters discuss non-parametrics, interval estimation, point estimation, asymptotics, Bayesian procedure, and deviation theory. Student familiarity with standard statistical techniques is assumed.},
	language = {en},
	publisher = {CRC Press},
	author = {Cox, D. R. and Hinkley, D. V.},
	month = sep,
	year = {1979},
	keywords = {Mathematics / Probability \& Statistics / General},
}


@inproceedings{Hable2009DataBasedDU,
  title={Data-Based Decisions under Complex Uncertainty},
  author={Robert Hable},
  year={2009},
  url={https://api.semanticscholar.org/CorpusID:11222776}
}

@article{martin_false_2019,
	title = {False confidence, non-additive beliefs, and valid statistical inference},
	volume = {113},
	issn = {0888613X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0888613X19300696},
	doi = {10.1016/j.ijar.2019.06.005},
	language = {en},
	urldate = {2025-05-17},
	journal = {International Journal of Approximate Reasoning},
	author = {Martin, Ryan},
	month = oct,
	year = {2019},
	pages = {39--73},
	file = {Eingereichte Version:/Users/maximwinter/Zotero/storage/ZXSXN8E3/Martin - 2019 - False confidence, non-additive beliefs, and valid statistical inference.pdf:application/pdf},
}

@article{martin_inferential_2013,
	title = {Inferential {Models}: {A} {Framework} for {Prior}-{Free} {Posterior} {Probabilistic} {Inference}},
	volume = {108},
	shorttitle = {Inferential {Models}},
	doi = {10.1080/01621459.2012.747960},
	abstract = {Posterior probabilistic statistical inference without priors is an important but so far elusive goal. Fisher's fiducial inference, Dempster--Shafer theory of belief functions, and Bayesian inference with default priors are attempts to achieve this goal but, to date, none has given a completely satisfactory picture. This paper presents a new framework for probabilistic inference, based on {\textbackslash}emph\{inferential models\} (IMs), which not only provides data-dependent probabilistic measures of uncertainty about the unknown parameter, but does so with an automatic long-run frequency calibration property. The key to this new approach is the identification of an unobservable auxiliary variable associated with observable data and unknown parameter, and the prediction of this auxiliary variable with a random set before conditioning on data. Here we present a three-step IM construction, and prove a frequency-calibration property of the IM's belief function under mild conditions. A corresponding optimality theory is developed, which helps to resolve the non-uniqueness issue. Several examples are presented to illustrate this new approach.},
	journal = {Journal of the American Statistical Association},
	author = {Martin, Ryan and Liu, Chuanhai},
	month = mar,
	year = {2013},
	pages = {301--313},
	file = {Eingereichte Version:/Users/maximwinter/Zotero/storage/8ZD65GYA/Martin und Liu - 2013 - Inferential Models A Framework for Prior-Free Posterior Probabilistic Inference.pdf:application/pdf},
}

@book{noauthor_kolmogoroff_nodate,
	title = {Kolmogoroff ( 1933) {Grundbegriffe} {Der} {Wahrscheinlichkeitsrechnung}},
	url = {http://archive.org/details/kolmogoroff-1933-grundbegriffe-der-wahrscheinlichkeitsrechnung},
	abstract = {Foundations of Probability},
	language = {ger},
	urldate = {2025-05-19},
	keywords = {Probability},
}