% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{report}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage[style=numeric]{biblatex}
\addbibresource{Sources.bib}

\usepackage{enumitem}
\usepackage{mathrsfs}


\usepackage{geometry}
\geometry{a4paper,top=35mm,bottom=30mm,textwidth=160mm}
% \usepackage{chngcntr}

\renewcommand{\thechapter}{\Roman{chapter}}

\usepackage{tocloft}

\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]

\renewcommand{\cftchapnumwidth}{2em}
\renewcommand{\cftsecindent}{2em}
\renewcommand{\cftsubsecindent}{5em}
\setlength{\cftbeforechapskip}{1em} % Kapitel-Abstand im TOC
\setlength{\cftbeforesecskip}{0.5em}
\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\thesubsection}{\thesection.\arabic{subsection}}
\renewcommand{\thesubsubsection}{\thesubsection.\arabic{subsubsection}}
%\setcounter{chapter}{-1}
\counterwithout{section}{chapter}

\usepackage{tikz}
\usetikzlibrary{bayesnet}
\tikzset{
      dot hidden/.style={},
      line hidden/.style={},
      dot colour/.style={dot hidden/.append style={color=#1}},
      dot colour/.default=black,
      line colour/.style={line hidden/.append style={color=#1}},
      line colour/.default=black
    }
\NewDocumentCommand{\drawdie}{O{}m}{%
      \begin{tikzpicture}[x=1em,y=1em,radius=0.1,#1]
        \draw[rounded corners=0.5,line hidden] (0,0) rectangle (1,1);
        \ifodd #2
          \fill[dot hidden] (0.5,0.5) circle;
        \fi
        \ifnum #2>1
          \fill[dot hidden] (0.2,0.2) circle;
          \fill[dot hidden] (0.8,0.8) circle;
        \fi
        \ifnum #2>3
          \fill[dot hidden] (0.2,0.8) circle;
          \fill[dot hidden] (0.8,0.2) circle;
        \fi
        \ifnum #2>5
          \fill[dot hidden] (0.8,0.5) circle;
          \fill[dot hidden] (0.2,0.5) circle;
        \fi
      \end{tikzpicture}%
    }


\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{biblatex}
\addbibresource{Sources.bib}
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\author{}
\date{}

\begin{document}


\renewcommand{\contentsname}{Contents}
\tableofcontents
\addtocontents{toc}{\protect\thispagestyle{empty}}

\newpage

\section{Introduction}

The most common classification of probabilities distinguishes between
objective, frequentist probability and subjective, Bayesian probability.
As practical as this naive distinction has proven to be, it is
worthwhile to take a closer look at the different facets of probability
in order to better understand its role in statistics and across
different schools of inference.

The historical development of probability
theory\footnote{The following historical summary is primarily based on \cite{shafer_origins_2018}.}
has been far from smooth. Compared with other mathematical and
philosophical disciplines it seems as, for some reason, both
mathematicians and philosophers had remarkable struggles to formalize
and to deal with probability. Or as the British mathematician Bertrand
Russell stated in 1929
``\textit{Probability is the most important concept in modern science, expecially as nobody has the slightest notion what it means.}''
\cite{sep-probability-interpret}.

Though probability had practical and theoretical relevance for a long
time, there is no calculus of probability before the seventeenth
century. Until then, probability was handled qualitatively and mainly
applied to propositions \cite{sep-probability-interpret}. The classical
definition of probability wasn't introduced until the early 18th century
by Jacob Bernoulli and Abraham De Moivre. At this stage, closely related
to gamble settings, probability is seen as the fraction of the total
number of possibilities in which a event of question occurs. In the
following 200 years many attempts were made to extend the classical
framework. In the early 19th century, attempts were made to develop a
geometric foundation and with the invention of measure theory some
mathematicians saw a strong connection to probability calculus. The
mathematics of the 20th century was marked by a strong movement toward
axiomatization, heavily influenced by David Hilbert and his 1921
proposal, now known as Hilbert's Program \cite{sep-hilbert-program}. In
line with this movement 1933 Andrei Kolmogorov published
\textit{Grundbegriffe der Wahrscheinlichkeitsrechnung} which set the
foundation of modern probability calculus where he wrote in the preface:

\begin{quote}
“The purpose of this monograph is to give an axiomatic foundation for the theory of probability. The author set himself the task of putting in their natural place, among the general notions of modern mathematics, the basic concepts of probability theory—concepts which until recently were considered to be quite peculiar.” \footnote{The English translation is taken from \cite[p. 15]{a_n_kolmogorov_foundations_1950}.} \cite[p.15]{noauthor_kolmogoroff_nodate}. 
\end{quote}

Kolmogorov saw probability from a frequentistic perspective. In his
chapter about elementary theory of probability, where he discussed
probability in a finite setting, he added the section ``The Relation to
Experimental Data'' where he briefly described how the theory of
probability is applied to the actual world of experiments:

\begin{quote}
\begin{enumerate}[label=\arabic*)]
  \item "There is assumed a complex of conditions, $\mathfrak{G}$, which allows of any number of repetitions."
  \item "We study a definite set of events which could take place as a result of the establishment of the conditions $\mathfrak{G}$. In individual cases where the conditions are realized, the events occur, generally, in different ways. Let $E$ be the set of all possible variants $\xi_1, \xi_2, ...$ of the outcome of the given events. Some of these variants might in general not occur, We include in the set $E$ all the variants which we regard \textit{a priori} as possible."
  \item "If the variant of the events which has actually occurred upon realization of conditions $\mathfrak{G}$ belongs to the set $A$ (defined in any way), then we say that the event $A$ has taken place."\footnote{Kolmogorov mentioned, that this section is not of interest for reader who are only interested in the purely mathematical develepment of his theory only. The axiomatic framework stands independently of this interpretative view.}
\end{enumerate}
\end{quote}

Some interesting insights on probability and the controversies on
different standpoints were offered by the German mathematician and
philosopher Rudolf Carnap:

\begin{quote}
"The various theories of probability are attempts at an explication of what is regarded as the prescientific concept of probability. In fact, however, there are two fundamentally different concepts for which the term probability is in general use. The two concepts are as follows, here distinguished by subscripts.
\begin{enumerate}[label=(\arabic*)]
  \item $\text{Probability}_1$ is the degree of confirmation of a hypothesis $h$ with respect to an evidence statement $e$, e.g., an observational report. This is a logical, semantical concept. A sentence about this concept is based, not on observation of facts, but on logical analysis; if it is true, it is L-true\footnote{L-true refers here to "logically true" which means that the truthfullnes is depends on a (formal) logical representation instead of empirical facts.} (analytic).
  \item $\text{Probability}_2$ is the relative frequency (in the long run) of one property of events or things with respect to another. A sentence about is concept is factual, empirical." \cite[p.19]{carnap_logical_1950}.
\end{enumerate}
\end{quote}

It is worth noting that Carnap also treats \(\text{probability}_1\) as
an objective concept:

\begin{quote}
"Deductive logic may be regarded as the theory of the relation of logical consequence, and inductive logic as the theory of another concept which is likewise objective and logical, viz., $\text{probability}_1$ or degree of confirmation. That $\text{probability}_1$ is an objective concept means this: if a certain $\text{probability}_1$ value holds for a certain hypothesis with respect to a certain evidence, then is value is entirely independent of what any person may happen to think about these sentences, just as the relation of logical consequence is independent in this respect." \cite[p.43]{carnap_logical_1950}.
\end{quote}

The multifaceted nature of probability still makes it hard to formalize
and unify into a single coherent theory. Probability is expected to
capture classical probability calculus while also being appropriate for
modeling existing evidence and, more broadly, information based
reasoning under uncertainty. In the context of statistical inference,
probability serves dual roles: as a mathematical framework for modeling
randomness (frequentist view) and as a measure of belief or uncertainty
(Bayesian view). These interpretations lead to different methodologies
and philosophical foundations, making unification challenging.
Nonetheless, both approaches aim to derive meaningful conclusions from
data in the presence of uncertainty. A probabilistic representation of
the truth value of assumptions should align with the real world. If
inference methods tended to assign high degrees of belief to false
assumptions and low degrees of belief to true ones, they would be highly
misleading and systematically deceptive. A requirement for ``meaningful
conclusions'' must be that the probabilistic representation is
\textit{calibrated} in the sense that false assumptions are typically
assigned low degrees of belief, and it is rare for them to receive high
degrees of belief, and vice versa for true assumptions
\cite{martin_false_2019}. This requirement aligns well with the
\textit{Cournot's principle} which was firstly stated by Jacob Bernoulli
in 1713 and later further developed by Antoine-Augustin Cournot and can
be seen as an early attempt to bridge probability calculus with the real
world:

\begin{quote}
"An event with very small probability is morally impossible; it will not happen. Equivalently, an event with very high probability is morally certain;" \cite{shafer_origins_2018}.
\end{quote}

It also resonates with the weak repeated sampling principle, as stated
by Cox and Hinkley

\begin{quote}
"The weak version of the repeated sampling principle requires that we should not follow procedures which for some possible parameter values would give, in hypothetical repetitions, misleading conclusions most of the time." \cite[p.~45--46]{cox_theoretical_1979}.
\end{quote}

In this sense, \textit{false confidence} should be avoided. Accordingly,
the following statement from a paper on the false confidence phenomenon
in satellite conjunction analysis, where reliable collision risk
assessment is a serious concern, can only be seen as concerning:

\begin{quote}
"Every real-world risk analysis problem involves a proposition of interest that is determined by
the structure of the problem itself; e.g. ‘Will these two satellites collide?’. Just as the practitioner will not seek out propositions strongly affected by false confidence, neither do practitioners have the option of avoiding such propositions when they arise." \cite{balch_satellite_2019}.
\end{quote}

Inferential models, as a modern framework for ``prior-free posterior
probabilistic inference'', introduced by Ryan Martin and Chuanhai Liu
\cite{martin_inferential_2013}, are capable of offering, under certain
conditions, calibration properties which can constrain false confidence.

In the following chapters, I will explain in more detail what is meant
by false confidence, how and why it may lead to problems. To motivate
this discussion, I will introduce key ideas from imprecise probability
theory and fiducialism, and then explore their connection to inferential
models.

\begin{center}
\vspace{1cm}
\begin{tikzpicture}[->, >=stealth, node distance= 1 cm, scale=0.8, transform shape]
\useasboundingbox (-0.5, -2) rectangle (9.5, 4.5);

    \node (1) at (1, 3.5) [draw,ellipse,minimum size=0pt,inner sep=2pt,scale=1, line width = 0.25mm] {\shortstack{Imprecise \\ Probability}};
    
    \node (2) at (3.5, 0.5) [draw,ellipse,minimum size=0pt,inner sep=3pt,scale=1, line width = 0.25mm] {\shortstack{Frequentism}};
    
    \node (3) at (4, -0.5) [draw,ellipse,minimum size=0pt,inner sep=2pt,scale=1, line width = 0.25mm] {\shortstack{Bayesianism}};
    
    \node (4) at (6.5, 2) [draw,ellipse,minimum size=0pt,inner sep=2pt,scale=1, line width = 0.25mm] {\shortstack{Generalized \\ Fiducial \\ Inference}};  
    
    \node (5) at (9.5, 0) [draw,ellipse,minimum size=0pt,inner sep=2pt,scale=1.1, line width = 0.3mm] {\shortstack{{Inferential} \\ {Models}}};
    
    \node (6) at (6, 4.5) [draw,ellipse,minimum size=0pt,inner sep=2pt,scale=1, line width = 0.25mm] {\shortstack{Random Set \\ Theory}};
    
    \node (7) at (3, 2) [draw,ellipse,minimum size=0pt,inner sep=3pt,scale=1, line width = 0.25mm] {\shortstack{Fiducial \\ Inference}};
  
    \node (8) at (5, -2) [draw,ellipse,minimum size=0pt,inner sep=2pt,scale=1, line width = 0.25mm] {\shortstack{Possibility \\ Theory}};
    
    \draw[->, line width = 0.3mm] (1) to[out = -140, in = 180, looseness=1.4] (8);
    \draw[->, line width = 0.3mm] (1) to[out = 35, in = 171, looseness= 0.64] (6);
    \draw[->, line width=0.3mm, dash pattern=on 3pt off 2pt] (2) to[out = 180, in = -180, looseness=1.8] (7);
    \draw[->, line width=0.3mm, dash pattern=on 3pt off 2pt] (3) to[out = 180, in = -180, looseness=1.9] (7);   
    \draw[->, line width = 0.3mm] (2) to[out = 0, in = 30, looseness=1.6] (8);
    \draw[->, line width = 0.3mm] (3) to[out = 0, in = 30, looseness=1.6] (8);     
    \draw[->, line width = 0.3mm] (7) to[out = 0, in = -180, looseness=1.7] (4);
    \draw[->, line width = 0.3mm] (8) to[out = 0, in = -180, looseness=1.4] (5); 
    \draw[->, line width = 0.3mm] (4) to[out = -55, in = -180, looseness=1.2] (5); 
    \draw[->, line width = 0.3mm] (6) to[out = -8, in = 90, looseness=1.12] (5);
    \draw[->, line width = 0.3mm] (4) to[out = 0, in = 90, looseness=1.2] (5);
\end{tikzpicture}
\vspace{0.5cm}
\end{center}

\section{Different types of probability}

\subsection{Probability measure}

In this section, I will revisit some essential concepts from probability
calculus in order to later highlight key differences from the
established mathematical notion of probability. The underlying structure
of the measure-theoretic construction of probability is based on
specific types of set systems that exhibit useful structural properties
--- so-called \(\sigma\)-algebras. In measure theory, the symbol
\(\sigma\) typically denotes (at most) countably infinite.

\begin{definition}[Sigma-Algebra]
Let $\Omega$ be a set and $\mathcal{P}(\Omega)$ denote the power set over $\Omega$. Then $\mathcal{F} \subseteq \mathcal{P}(\Omega)$ is called a $\sigma$-Algebra if 
\begin{enumerate}
  \item $\emptyset \in  \mathcal{F}$
  \item $A \in \mathcal{F} \Rightarrow A^C \in \mathcal{F}$
  \item $(A_n)_{n \in \mathbb{N}} \subseteq \mathcal{F} \Rightarrow \displaystyle\bigcup_{n \in \mathbb{N}} A_n \in \mathcal{F}$
\end{enumerate}
holds. The tupel $(\Omega, \mathcal{F})$ is then called a {measurable space}.
\end{definition}

Therefore \(\sigma\)-algebras are non-empty collections of sets that
contain the empty set and are closed under complementation and countable
unions. Simplified, finite cases can often be seen as special cases of
countably infinite ones by extending a finite index set
\(I = \{1, \dots, k \}\) to a countable one by defining
\(A_i = \emptyset \quad \text{for } i > k\) so that a finite union
\(\bigcup_{i=1}^{k} A_i\) can be rewritten as a countable union
\(\bigcup_{i=1}^{\infty} A_i,\) with \(A_i = \emptyset\) for all
\(i > k\).

\begin{definition}[Measure]
Let $(\Omega, \mathcal{F})$ be a measurable space. A set-function $\mu : \mathcal{F} \rightarrow \mathbb{R}$ is called a {measure} if it fulfils
\begin{enumerate}
  \item $\mu(\emptyset) = 0$ 
  \item $\mu(A) \geq 0 \quad \forall \, A \in \mathcal{F}$ \quad (Non-negativity)
  \item For any sequences of pairwise disjunct sets $A_i \in \mathcal{F}, \, i \geq 1$: \newline
    $\mu \big(\bigcup_{i=1}^{\infty} A_i \big) = \sum_{i=1}^{\infty} \mu(A_i)$ \quad ($\sigma$-additivity)
\end{enumerate}
The tupel $(\Omega, \mathcal{F}, \mu)$ is called a \textit{measure space}. Measures that are normed to $\mu(\Omega) = 1$ (normalization property) are called a \textit{probability measure} and will be noted with $\mathbb{P}$. In the context of probability calculus $(\Omega, \mathcal{F}, \mathbb{P})$ is called a probability space, $\Omega$ a \textit{sample space} and $\mathcal{F}$ an \textit{event space}.
\end{definition}

Among the unfortunate terminological choices in statistics, random
variable is perhaps one of the most misleading since they are neither
random, nor variables by nature.

\begin{definition}[Random variable]
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and $(\Omega', \mathcal{F}')$ a measurable space. A function $X: \Omega \rightarrow \Omega'$ is a \textit{random variable} if 
$$ \{\omega \, | \,  \omega \in \Omega \, \land \, X(w) \in A \} = X^{-1} (A) \in \mathcal{F} \quad \forall A \in \mathcal{F}' \quad (\mathcal{F}-\mathcal{F}'-\text{measurability})$$
is satisfied. Using this definition the measurable space $(\Omega', \mathcal{F}')$ can be extended to a probability space through \mbox{$(\Omega, \mathcal{F}, \mathbb{P}) \xrightarrow{X} (\Omega', \mathcal{F}', \mathbb{P}_X)$} where the according \textit{push-forward-measure} $\mathbb{P}_X$ is defined through 
$$\mathbb{P}_X (A) := \mathbb{P}(X \in A) \overset{}{=} \mathbb{P} (\{\omega | \omega \in \Omega \land X(\omega) \in A \}) \overset{\text{}}{=} \mathbb{P}( \underbrace{X^{-1} (A)}_{\in \mathcal{F}}) \in [0,1] \quad \forall A \in \mathcal{F}'.$$
\end{definition}

\begin{definition}[Information]
Let $(\Omega, \mathcal{F})$ be a measurable space. \textit{Information} can be characterized as a subset $\mathcal{A} \subseteq \mathcal{F}$ of events we are capable of evaluating as having occurred or not\cite{Hable2009DataBasedDU}.

Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $(\Omega', \mathcal{F}')$ a measurable space and $X$ an \textit{observable} $\mathcal{F}-\mathcal{F}'-\text{measurable}$ random variable. Then $\mathcal{A}_X = \{X^{-1}({A}) \mid {A} \in {\mathcal{F}'}\} \subseteq \mathcal{F}$ represents through $X$ \textit{observable} information.
\end{definition}

\begin{example}[Colored dice I]
Consider a dice that is numbered and has coloured faces like this: $\Omega = \Big\{
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=blue, opacity=0.47}]{1}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=blue, opacity=0.47}]{2}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=white, opacity=0.5}]{3}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=0.6}]{4}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=0.6}]{5}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=0.6}]{6}}
\Big\}$.

If we are interested in the face values we can simply map the face values to the according numbers $X: \Omega \rightarrow \{1, 2, 3, 4, 5, 6\}$. For each realization of $X$ we can exactly know which events did occur or not. If we instead map to colours by $Y: \Omega \rightarrow \{blue, white, green\}$ some information is lost. If e.g. a green face was rolled, we can not know which of the green sides $\Big\{
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=0.6}]{4}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=0.6}]{5}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=0.6}]{6}}
\Big\}$ was rolled based on the piece of information "it was \textit{green}". 
\end{example}

\section{False confidence and validity critereon}

\section{Imprecise probability theory}

The term \textit{imprecise probability} does not refer to a particular
theory, but rather to a collection of different approaches that share a
common feature of imprecision. In contrast to probability measures,
imprecise probabilities are generally not additive. Some approaches can
be seen as a extension of the measure theoretic based probability
theory, like \textit{random sets}, while others might have a
non-measure-theoretic foundation. In this chapter I will give deliver
some motivation for imprecise probabilities in general and introduce
some popular concepts of imprecise probabilities.

\begin{example}[Prisoners dilemma I]
Consider a variation of the prison dilemma used in game theory, but from our perspective as a policeman. Assume there a two suspects of a crime, person $A$ and $B$, where it is known, that exactly one of them must be guilty. If $A$ is guilty $B$ can not be guilty and otherwise. We, as a policeman, interrogate $A$ without knowing anything about person $B$. After the interrogation a college asks about our opinion, how probable it is, that person $A$ is guilty.

\begin{quote}
College: \textit{What do you think is the probability that person A is guilty?} \par
Policeman: \textit{I think the probability is around 20\%.} \par
College: \textit{I see. So you assume the probability that person B is guilty must be around 80\%?}
\end{quote}

Although being intuitively clear how our college came to this conclusion, his response might seem puzzling. Our college implicitly chose $\Omega = \{\mathbf{A} \text{ is guilty}, \mathbf{B} \text{ is guilty} \}$ as sample space and $\mathcal{F} = \{ \emptyset, \{ \mathbf{A} \text{ is guilty} \}, \{ \mathbf{B} \text{ is guilty} \}, \{ \mathbf{A} \text{ is guilty}, \mathbf{B} \text{ is guilty} \} \}$ as event space. Simple probability calculus shows that $P(\{A \text{ is guilty}\}) \, = \, 0.2$ implies $P(\{B \text{ is guilty}\}) \, = \,  0.8$.

\begin{align*}
1 \ &= \ P(\Omega) & \text{(normalization)}\\
  &= \ P(\{\mathbf{A} \text{ is guilty}, \, \mathbf{B} \text{ is guilty}\}) \\
  &= \ P(\{\mathbf{A} \text{ is guilty}\} \, \dot\cup \, \{\mathbf{B} \text{ is guilty}\}) & \text{}\\
  &= \ P(\{\mathbf{A} \text{ is guilty}\}) + P(\{\mathbf{B} \text{ is guilty}\}) & \text{(additivity)}\\
  & \Leftrightarrow \\
P(\{\mathbf{B} \text{ is guilty}\}) \ &= \ 1 - P(\{\mathbf{A} \text{ is guilty}\})
\end{align*}


Depending on the way someone interprets the statement "I think the probability is around 20\%.", this result might be more or less troubling. It is thinkable that a very experienced policeman had encountered many sufficiently similar situations to determine a relative frequency based solely on the information he gathered from interrogating $A$, without any knowledge of $B$. Based on such a reading, the above conclusion seems quite reasonable - even though such a perspective might be quite uncommon in this context. Rather, one may interpret such an educated guess as a quantification of the strength of belief or a vague quantification of how the currently known evidence supports the assumption of $A$'s guilt. However, it would seem highly unfair to hold a strong bias against $B$ in this situation, or even to infer stronger evidence for $B$’s guilt from weak evidence against $A$. I want to stress the fact that the additivity property has an important implication. By taking belief mass away from “$A$ is guilty”, it must be shifted to “$B$ is guilty”, even though this shift is not supported by any information concerning $B$. It therefore might seem reasonable to consider addressing certain problems using more weakly structured, non-additive alternatives.
\end{example}

\subsection{Possibility measures}

\subsubsection{Boolean possibility theory}

Boolean possibility theory is based on propositional logic where the
Pinciple of Bivalence states that every proposition \(p\) is either true
(1) or false (0). But instead of focusing directly on propositions the
focus lies in modelling a rational agents belief about propositions. The
current knowledge of an agent is represented by a \textit{belief base}
\(K\) which contains boolean formulas. \(K\) is required to be
\textit{consistent} i.e.~it must be free of logical contradictions.

If a proposition \(p\), based on \(K\), is logically true, the agent
must believe \(p\) to be true, written as \(N(p) \, = \, 1\) and
\(N(p) \, = \, 0\) otherwise.

An agents state of belief is then represented by the pair
\((N(p), \, N(\lnot p))\) with 3 possible states:

\begin{itemize}
  \item $(N(p), \, N(\lnot p)) = (1, \, 0)$ agent believes $p$
  \item $(N(p), \, N(\lnot p)) = (0, \, 1)$ agent believes $\lnot p$
  \item $(N(p), \, N(\lnot p)) = (0, \, 0)$ agent is completely ignorant about $p$
\end{itemize}

\((N(p), \, N(\lnot p)) = (1, \, 1)\) is not a possible state since
\(p \, \land \, \lnot p\) is a contradiction and can not be derived by a
consistent belief base. It is important to notice that
\(N(p) \, = \, 0\) does not imply \(N( \lnot p) \, = \, 1\) since an
agent is allowed to be fully ignorant. Therefore the question arises if
a certain proposition is consistent with \(K\). If \(p\) is consistent
with \(K\) this relation is stated by \(\Pi (p) \, = \, 1\). The
relation between \(N\) and \(\Pi\) is given through
\(\Pi (p) \, = \, 1 - N(\lnot p)\) and furthermore
\(N (p \land q) \, = \, \min \big( N(p), N(q) \big)\) and
\(\Pi (p \lor q) \, = \, \max \big( \Pi(p), \Pi(q) \big)\).

\begin{example}[Prisoners dilemma II]
This framework enables us to model the initial situation in two particular cases. In the case where no suspect has yet been interrogated and nothing is known about either suspect (complete ignorance), and in the case where, after the interrogation of one (or possibly both) suspects, the guilt or innocence of a suspect is certain (complete knowledge).

The first case reveals a notable difference from a Bayesian flat prior approach. Instead of assuming a prior guilt (or innocence) of 0.5 for each suspect under ignorance, we can now adopt a more sophisticated perspective. The belief base contains our information that exactly one of the two suspects is guilty. $N(A \text{ is guilty} \, \lor \, B \text{ is guilty}) = 1$. On the other hand there is no reason to believe in the guilt of $A$ or $B$ separately $N(A \text{ is guilty}) = N(B \text{ is guilty}) = 0$. On the other hand there is no reason to doubt that one of the subjects is innocent $\Pi(A \text{ is guilty} \, \lor \, B \textit{ is guilty}) = \Pi (A \text{ is guilty}) = \Pi (B \text{ is guilty}) = 1$. 

In the second case e.g. for $N(A \text{ is guilty}) = 1$ it directly follows through $\Pi(A) \text{ is not guilty}) = 1 -  N(A \text{ is guilty}) = 0$ and $A \text{ is guilty} \Leftrightarrow B \text{ is not guilty}$ that $B$ must be believed to be innocent. The situation where an agent has incomplete knowledge between \textit{complete ignorance} and \textit{complete knowledge} can not be modelled so far.
\end{example}

A thought experiment suggests, without claiming to present a fully
developed theory, how we can bridge this logical concept to the more
familiar measure theory. Imagine a hypothetical universe consisting of
many different worlds. Each world corresponds to a logical state and
must be free of logical contradictions. By asking a question ``How
probable is \(p\)?'' can thereby be understood as a question of ``How
probable is it to exist in a world where \(p\) is true?''. Such
probabilistic reasoning then follows roughly the following scheme. We
must first consider which type of worlds qualify, so that only those
sufficiently similar to our own are taken into account. This is very
similar to narrowing down the population in statistical studies or
considering theoretical assumptions and experimental conditions in
physics. Then we narrow down the logical variables of interest. Only
looking at these variables some worlds are indistinguishable and can be
organized into sets \(\omega\) representing such worlds with
indistinguishable states. Let \(\Omega\) denote the set that contains
the resulting categories \(\omega\) and \([p] \subseteq \Omega\)
describe the conditions where \(p\) is true. We then refer to the
conditions \([p]\) as the models of \(p\). A proposition \(p\) is
believed to be true if \([K] \subseteq [p]\) and believed to be false if
\([K] \subseteq [p]^C\). If a proposition allows for at least one
setting where it could be true it is considered to be \textit{possible}.
If a proposition is true in every setting it is \textit{necessary} to
believe in it.

\subsubsection{Fuzzy set theory}

The link to set-theoretic measure theory permits the incorporation of
fuzzy set theory.

\begin{definition}[Fuzzy set, membership function]
Let $X$ be a set. A \textit{fuzzy set} $\tilde{A}$ in $X$ is a collection of ordered pairs of the form
$$\tilde{A} = \big\{ (x, \mu_{\tilde{A}}(x)) \, | \, x \in X \big\}.$$
$\mu_{\tilde{A}}: X \rightarrow L, \sup(L) < \infty$ is called the membership function (or generalized characteristic function). For $\mu_{\tilde{A}} (x) = 1$ the fuzzy set is \textit{normalized}. For $L = [0,1]$. $L$ is called a \text{possibility scale}.
\end{definition}

\begin{definition}[$\alpha$-cut]
The set of elements that belong to $\tilde{A}$ at least to the degree $\alpha$ is called a $\alpha$-\textit{cut}:
$$A_{\alpha} = \big\{ x \, | \, x \in X, \, \mu_{\tilde{A}} \geq \alpha \big\}$$
and $A_{\alpha}' = \big\{ x \, | \, x \in X, \, \mu_{\tilde{A}} > \alpha \big\}$ defines a \textit{strong} $\alpha$-\textit{cut}. 
\end{definition}

Here are a few useful basic operations on fuzzy sets
\(\tilde{A}, \, \tilde{B}\):

\begin{itemize}
  \item Intersection (corresponding to a logical and): $\mu_{\tilde{A} \cap \tilde{B}} := \min \big( \mu_{\tilde{A}} (X), \, \mu_{\tilde{B}} (X) \big) \ \forall x \in X$
  \item Union (corresponding to an exclusive\footnote{An inclusive or in $A \lor B$ describes a relation where A, B or A and B together are true. An exclusive or in $A \dot\lor B$ describes a relation where only A or B can be true, but not A and B together.} or): $\mu_{\tilde{A} \cup \tilde{B}} := \max \big( \mu_{\tilde{A}} (X), \, \mu_{\tilde{B}} (X) \big) \ \forall x \in X$ 
  \item Complement (corresponding to a negation): $\mu_{\tilde{A}} (X) := 1 - \mu_{\tilde{A}} (X) \ \forall x \in X$
\end{itemize}

\subsubsection{Numeric possibility theory}

The key idea behind numeric possibility theory is that the current state
of an agents incomplete knowledge can be captured by a
\textit{possibility distribution} and thus can be seen as an extension
of boolean possibility theory.

\(\pi: \mathcal{X} \rightarrow [0, 1]\) and the consistency assumption,
that \(\pi (x) = 1\) is fulfilled for at least one \(x \in X\).
\(1 - \pi (x)\) might be interpreted as an agents surprise that \(X\)
turns out to be \(x\). A possibility distribution could be e.g.~derived
by intuition, an experts opinion or an assumed distribution. A
\textit{possibility measure} is defined as a set function that maps from
\(\mathcal{P} (\mathcal{X})\) to \([0,1]\)

Possibility contour \(\pi: \mathcal{X} \rightarrow [0, \, 1]\) with
\(\sup_x \pi (x) = 1\) Possibility measure
\(\Pi: \mathcal{P}(\mathcal{X}) \rightarrow [0, \, 1], \ A \mapsto \sup \pi (x), A \subseteq \mathcal{X}\)

\subsection{Random sets}

\begin{example}[Coloured dice II]
Consider a coloured dice that looks like this: $\Omega = \Big\{
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=blue, opacity=0.47}]{1}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=blue, opacity=0.47}]{2}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=red, opacity=0.5}]{3}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=0.6}]{4}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=0.6}]{5}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=1}]{6}}
\Big\}$ and the random variable $Y \rightarrow \{blue, red, green \}$.

Given such a dice many people wouldn't struggle at all to precisely observe which colour was rolled while for some people it might be completely. $Y$ is obviously only partially observable for people with red-green colour blindness since it could be look like this: $\Omega = \Big\{
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=blue, opacity=0.47}]{1}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=blue, opacity=0.47}]{2}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=red, opacity=0.5}]{3}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=0.6}]{4}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=0.6}]{5}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=1}]{6}}
\Big\} \ \rightarrow \ \Omega_{Obs} = \Big\{
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=blue, opacity=0.47}]{1}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=blue, opacity=0.47}]{2}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=gray, opacity=0.55}]{3}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=gray, opacity=0.55}]{4}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=gray, opacity=0.55}]{5}},
\raisebox{-3pt}{\drawdie[line hidden/.append style={fill=gray, opacity=0.85}]{6}}
\Big\}$. 

So the question arises how to deal with such a situation? Assume, that some extra knowledge about that dice is provided: The faces can only be blue, red or green, but not all of those colours must be presented on the dice. Green is the only colour that can also come with a darker shade. The probability of being rolled is the same for all faces.

$$
\begin{array}{cc}
\hspace{-17 pt}
Y(\omega) =
\begin{cases}
blue & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=blue, opacity=0.47}]{1}}, \\
blue & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=blue, opacity=0.47}]{2}}, \\
red & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=red, opacity=0.5}]{3}}, \\
green & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=0.6}]{4}}, \\
green & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=0.6}]{5}}, \\
green & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=1}]{6}}.
\end{cases}
&  \quad
\textbf{?} =
\begin{cases}
\{blue\} & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=blue, opacity=0.47}]{1}}, \\
\{blue\} & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=blue, opacity=0.47}]{2}}, \\
\{green, red\} & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=gray, opacity=0.6}]{3}}, \\
\{green, red\} & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=gray, opacity=0.6}]{4}}, \\
\{green, red\} & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=gray, opacity=0.6}]{5}}, \\
\{green\} & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=gray, opacity=0.85}]{6}}.
\end{cases}
\end{array} 
$$
On the left we can see the \textit{original} random variable $Y_0$ and on the right a failed attempt to write down a random variable.
\end{example}

\begin{definition}[Strong measurability, random set, derived from \cite{MIRANDA200532}]
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and $(\Omega', \mathcal{F}')$ a measurable space and $\Gamma: \Omega \rightarrow \mathcal{P}(\Omega')$ a multi-valued mapping. Given $A \in \mathcal{F}'$, its \textit{upper inverse} is given by $\Gamma^*(A) = \{\omega \, | \, \omega \in \Omega, \, \Gamma(\omega) \cap A \neq \emptyset \}$ and the \textit{lower inverse} is $\Gamma_*(A) = \{\omega \, | \, \omega \in \Omega, \, \emptyset \neq \Gamma(\omega) \subseteq A \}$. The multi-valued mapping $\Gamma$ is said to be \textit{strongly measurable} when $\Gamma^*(A)$ and $\Gamma_*(A)$ belong to $\mathcal{F}$ for all $A \in \mathcal{F}'$ and then be called a \textit{random set}.
\end{definition}

\begin{definition}[lower and upper probability]
Let $\Gamma: \Omega \rightarrow \mathcal{P}(\Omega')$ be a random set. For $A \in \mathcal{F}'$ the \textit{upper probability} is defined by $\overline{P}(A) := P^*_\Gamma (A) = \displaystyle\frac{\mathbb{P}(\Gamma^*(A))}{\mathbb{P}(\Gamma^*(\Omega))}$ and the \textit{lower probability} by $\underline{P} (A) := P_{*\Gamma} (A) = \displaystyle\frac{\mathbb{P}(\Gamma_*(A))}{\mathbb{P}(\Gamma^*(\Omega))}$.
\end{definition}

\begin{example}[Coloured dice II, continued] 

Here we face the situation that many random variables, $S(\Gamma) := \{Y: \Omega \rightarrow \Omega' \text{ is measurable} \, | \, Y(\omega) \in \Gamma(\omega) \, \forall \omega \in \Omega \}$, could potentially suit such an imprecise observation, we simply can not tell which one it exactly is. Consequently we can derive a set of suitable push-forward-measures $P(\Gamma) := \{P_Y \, | \, Y \in S(\Gamma) \}$ and a \textit{credal set} $M(\overline{P}) := \{Q \text{ is a probability} \, | \, Q(A) \leq \overline{P} (A) \, \forall A \in \mathcal{F}' \}$ that defines a class of probabilities that are dominated by the derivable upper probabilities.

$$
\begin{array}{cc}
\hspace{-17 pt}
Y_1(\omega) =
\begin{cases}
blue & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=blue, opacity=0.47}]{1}}, \\
blue & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=blue, opacity=0.47}]{2}}, \\
red & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=red, opacity=0.5}]{3}}, \\
red & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=red, opacity=0.5}]{4}}, \\
red & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=red, opacity=0.5}]{5}}, \\
green & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=1}]{6}}.
\end{cases}
&  ,..., \, 
Y_n(\omega) =
\begin{cases}
blue & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=blue, opacity=0.47}]{1}}, \\
blue & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=blue, opacity=0.47}]{2}}, \\
green & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=0.5}]{3}}, \\
green & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=0.6}]{4}}, \\
green & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=0.6}]{5}}, \\
green & \text{for } \omega = \raisebox{-3pt}{\drawdie[line hidden/.append style={fill=green, opacity=1}]{6}}.
\end{cases}
\end{array} 
$$
On the left we can see the random variable $Y_1$ that describes the scenario where $\mathbb{P}_{Y_1}(\{green \}) = \underline{P}(\{green \}) = \frac{1}{6}$ has the lowest and $\mathbb{P}_{Y_1}(\{red \}) = \overline{P}(\{red \}) = \frac{3}{6}$ has the biggest suitable probability. On the right we can see the scenario where $\mathbb{P}_{Y_n}(\{red \}) = \underline{P}(\{red \}) = 0$ has the lowest and $\mathbb{P}_{Y_n}(\{green \}) = \overline{P}(\{green \}) = \frac{4}{6}$ probability. In every scenario, since $blue$ faces can be precisely observed, holds $\mathbb{P}_{Y \in S(\Gamma)}(\{blue \}) = \underline{P}(\{blue \}) = \overline{P}(\{blue \}) = \frac{2}{6}$.

\end{example}

\section{Fiducialism}
\subsection{Fisher's original fiducial argument}

In 1930 Fisher introduced his idea the \textit{fiducial principle} which
turned out to be one of his most controversial ideas of his career. He
criticised the concept of \textit{inverse probability}, by which he
meant Bayes's postulate fundamental to Bayesian inference
\cite{aldrich_r_1997}.

\begin{quote}
"Inverse probability has, I believe, survived so long in spite of its unsatisfactory basis, because its critics have until recent times put forward nothing to replace it as a rational theory of learning by experience." \cite{Fisher_1930}
\end{quote}

He disregarded the subjective nature behind the Bayesian approach and
often inherently arbitrary choice of a particular \textit{a priori}
distribution for parameters. Therefore he tried to find a more objective
alternative that is closer to frequentist probabilities. Although being
convinced of the importance of his idea he failed to establish
fiducialism. Fisher could not provide a coherent and comprehensive
theory for fiducial inference and left behind a strongly limited theory,
mostly built around exemplary examples and several changes of mind that
lead to some confusion \cite{zabell_r_nodate}.

His proposed example takes a bivariate normal distribution with unknown,
fixed correlation \(\phi\) with a sample size of \(n=4\).

Let \(T\) be a statistic derived for observable sample correlations
\(r\) with distribution function
\(F(r; \phi) \, = \, P(T \leq r \, | \, \Phi = \phi)\).

Fisher reasoned that, under repeated sampling, each possible value of
\(\phi \in [-1,\,1]\) would be associated with a unique value of the
\(\gamma-\)quantile of the sampling distribution.

Therefore by looking up the related e.g.~0.95-quantile to an observed
sample correlation there is a corresponding \textit{fiducial}
0.05-value.

Therefore by looking up the related e.g.~0.95-quantile to an observed
sample correlation there is a corresponding \textit{fiducial}
0.05-value. Fisher stated this as a relation of the form
\(P = F(T, \theta)\), where \(T\) is a statistic of continuous
variation, \(P\) the probability, that \(T\) is less than any specified
value and \(\theta\) the fixed parameter of question. Therefore by
looking up the fiducial 0.05-value for an observed \(\theta\) we know

\subsection{Generalized Fiducial Inference}

\begin{definition}[Data generating equation]
A data generating equation (DGE) has the form $\mathbb{X} \ = \  G \, (\theta, \, U)$ and contains
\begin{itemize}
  \item observable data $\mathbb{X}$
  \item an association function $G$
  \item a random variable $U$ with known distribution $P_U$
  \item a parameter of interest $\theta$.
\end{itemize}
After the observation this results in $X \ = \ G \, (\theta, \, U^*)$ with
\begin{itemize}
  \item observed data $X$
  \item an unobserved realization $U^*$ (of $U$).
\end{itemize}
\end{definition}

This can be reformulated through
\(X \ = \ G \, (\theta, \, U^*) \ \, \Leftrightarrow \ \, \theta \ = \ G^{-1}(X, \, U^*)\).

The basic idea behind DGEs can be shown with a motivational example.

\begin{example}
Lets have a look at a simple normal distribution $Y \sim \mathcal{N}(\theta,\, \sigma^2)$. We are interested in the unknown parameter $\theta$. Now we can ask the question, which information would be sufficient to know the exact value of $\theta$ after observing e.g. X = (1.159) from $\mathcal{N}(2, 1.5^2)$
$$Y \sim \mathcal{N}(\theta,\, \sigma^2) = \theta + \mathcal{N}(0,\, \sigma^2), \quad U \sim \mathcal{N}(0,\, \sigma^2) \newline
\Rightarrow \ \theta \ = \ G^{-1}(X, \, U^*) \ = \ X - U^*$$
If the exact value of $U^* = -0.841$ was known, the true value of $\theta$ could directly be calculated by
$$\theta = X- U^* = 1.159 - (-0.841) = 2$$
\end{example}

So can we simply observe \(X\) and solve for
\(\theta \ = \ G^{-1}(X, U^*)\)? The required information about \(U^*\)
is typically not available and therefore the direct approach is not
feasible. But since the distribution of \(U \sim P_{U}\) is known a copy
of \(U\), denoted as \(u^* \sim P_U\), can be be repeatedly drawn. The
new relation \(X = G(\theta^*, u^*)\) contains observed (therefore
known) data, simulated (therefore known) sample of \(u*\) and a known
relation \(G\). Therefore \(\theta^*\) can be derived as a
\textit{random estimator} (or \textit{fiducial sample}) with an
according fiducial distribution.
\[\theta^*_{FD} \ = \ \text{argmin}_{\theta^*} \| \hspace{-0.3cm} \underbrace{X}_{\displaystyle{G(\theta, \, U^*)}} \! - \ G(\theta, u^*) \| \]

\section{Inferential models}

Ryan Martin defines defines inferential models as follows:

\begin{definition}[Inferential models, as given by \cite{martin_false_2019}]
Fix the sample space $\mathbb{Y}$, parameter space $\Theta$ and let $\mathscr{P} = \{P_{Y|\theta} : \theta \in \Theta\}$ be a statistical model. An inferential model is a map from $(\mathscr{P}, y, \dots)$ to a function 
$b_y : 2^{\Theta} \to [0,1]$, where $b_y(A)$ represents the analyst's belief 
in the assertion "$\theta \in A$".
\end{definition}

This definition seems to have been purposefully left vague and requires
further explanation.

\subsection{Inferential models based on random sets}

In the early stage of Inferential models the authors focused on IM
construction based on random sets suggested by the following procedure:

\begin{quote}
"\textit{A-step. } Associate the unknown parameter $\theta$ to each possible $(x, u)$ pair to obtain a collection of sets $\Theta_x(u)$ of candidate parameter values. \newline
\textit{P-step. } Predict $\mu*$ with a valid predictive random set $\mathcal{S}$. \newline
\textit{C-step. } Combine $X = x, \, \Theta_x (u)$, and $\mathcal{S}$ to obtain a random set $\Theta_x (\mathcal{S}) = \bigcup_{u \in {\mathcal{S}}} \Theta_x(u)$. Then, for any assertion $A \subseteq \Theta$, compute the probability that the random set $\Theta_x (\mathcal{S})$ is a subset of $A$ as a measure of the available evidence in supporting $A$"\cite{martin_inferential_2013}.
\end{quote}

The \textit{a(ssociation)-step} is basically the same as the stating a
data generating equation. The \textit{p(rediction)-step} is
conceptionally the same as the simulating samples from a copy of the
unobserved auxiliary random variable but with the major difference, that
an extra layer of impression is added by the usage of a random set. In
contrast to the GFI method, not simply just a single single random
estimate and a single fiducial distribution are derived, but instead a
set of random estimates and fiducial distributions. While GFI relies on
a arbitrary choice of one single auxiliary variable \(U\), which might
be or not be close to the true (or optimal) \(U_0\), a good choice of of
the random set \(\Gamma\) makes it more probable that \(U_0\) is
captured in \(S(\Gamma)\) which then makes it more probable, that the
true (or optimal) value for \(\theta\) is also captured. In particular,
from \(U_0 \in S(\Gamma)\), it follows that
\(\theta_0 \in \{ \theta \mid X = G(U, \theta) \} := \Theta_x(U)\) and
otherwise. The idea behind the \textit{c(ombination)-step} is pretty
simple. It suggests to construct, based on the results from the p-step,
a new random set. Based on this random set the lower probability can be
calculated to evaluate as an non-additive degrees of belief about any
assertion of the form \(A \subseteq \Theta\).


\printbibliography



\end{document}
